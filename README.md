# Explainable AI in Credit Decision-Making: A Multi-Layer Approach

**Master Thesis Project**  
**Author:** Jakob Lindner  
**Institution:** Nova SBE
**Year:** 2025

---

## ðŸ“‹ Abstract

This repository contains the complete implementation of a research study investigating the effectiveness of different explanation layers for AI-driven credit decisions. The system implements a within-subjects experimental design comparing four explanation approaches (Baseline SHAP, Interactive Dashboard, Narrative Explanation, and Counterfactual Analysis) across two borderline credit application scenarios.

**Research Question:** How do different explanation modalities affect user understanding, trust, and perceived fairness in AI credit decision systems?

---

## ðŸŽ¯ Key Features

### **Experimental Design**
- **Within-subjects design:** Each participant evaluates all explanation layers
- **2 Personas:** Borderline approved (53% confidence) and borderline rejected (47% confidence)
- **4 Explanation Layers:** Progressive disclosure from technical to narrative
- **3 Rating Dimensions:** Understanding, Communicability, Mental Ease (cognitive load inverted)
- **Comprehensive data collection:** Layer ratings, time spent, qualitative feedback

### **Technical Implementation**
- **Frontend:** Next.js 14 (React), TypeScript, TailwindCSS, Framer Motion
- **Backend:** FastAPI (Python), XGBoost ML model, OpenAI GPT-4o-mini for narratives
- **Database:** Supabase (PostgreSQL) with RLS policies
- **ML Model:** XGBoost trained on German Credit Dataset (1994)
- **Explainability:** SHAP (SHapley Additive exPlanations)
- **Deployment:** Railway (backend), Netlify (frontend)

---

## ðŸ“Š Explanation Layers

### **Layer 1: Baseline SHAP Table**
- Complete technical table showing all SHAP feature contributions
- Sorted by impact magnitude
- Color-coded risk indicators
- Designed for technical users

### **Layer 2: Interactive Dashboard**
- Visual risk tug-of-war showing factor balance
- Progressive disclosure with expandable feature cards
- Global distribution comparisons for numeric features
- Categorical comparisons with success rates
- Concise AI-generated analytical summary (<50 words)

### **Layer 3: Narrative Explanation**
- Natural language explanation (150-200 words)
- Specific benchmarks and percentiles
- Fairness statement (regulatory compliance)
- Actionable guidance for rejected applications
- Professional, defensible language

### **Layer 4: Counterfactual Analysis**
- "What-if" scenarios showing minimal changes to reverse decision
- Interactive feature adjustment
- Real-time prediction updates
- Exploration of decision boundaries

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND                             â”‚
â”‚  Next.js 14 + TypeScript + TailwindCSS + Framer Motion     â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Consent    â”‚â†’ â”‚   Personas   â”‚â†’ â”‚    Layers    â”‚     â”‚
â”‚  â”‚  & Baseline  â”‚  â”‚  (2 cases)   â”‚  â”‚  (4 types)   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â†“                                  â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                  â”‚ Post-Questionnaireâ”‚                       â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BACKEND                              â”‚
â”‚              FastAPI + Python + XGBoost                      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  XGBoost     â”‚  â”‚    SHAP      â”‚  â”‚   OpenAI     â”‚     â”‚
â”‚  â”‚  Predictor   â”‚â†’ â”‚  Explainer   â”‚â†’ â”‚  Narratives  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â†“                                  â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                  â”‚  Supabase (DB)   â”‚                       â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸš€ Quick Start

### **Prerequisites**
- Node.js 18+ and npm
- Python 3.11+
- Supabase account (for database)
- OpenAI API key (for narrative generation)
- Cloudflare R2 account (for model storage)

### **Environment Variables**

Create `.env` files in both `frontend/` and `backend/`:

**Frontend `.env.local`:**
```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

**Backend `.env`:**
```bash
# Database
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key

# OpenAI (for narrative generation)
OPENAI_API_KEY=your_openai_key

# Cloudflare R2 (for model storage)
R2_ACCOUNT_ID=your_r2_account_id
R2_ACCESS_KEY_ID=your_r2_access_key
R2_SECRET_ACCESS_KEY=your_r2_secret_key
R2_BUCKET_NAME=your_bucket_name
```

### **Installation**

**Backend:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

**Frontend:**
```bash
cd frontend
npm install
```

### **Database Setup**

Run the schema migration in Supabase SQL Editor:
```bash
# Execute the schema file
psql $DATABASE_URL -f backend/migrations/FINAL_CLEAN_SCHEMA.sql
```

### **Running Locally**

**Backend (Terminal 1):**
```bash
cd backend
source venv/bin/activate
uvicorn app.main:app --reload --port 8000
```

**Frontend (Terminal 2):**
```bash
cd frontend
npm run dev
```

Access the application at `http://localhost:3000`

---

## ðŸ“ Repository Structure

```
.
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ ARCHITECTURE.md              # Detailed technical architecture
â”œâ”€â”€ PROJECT_OVERVIEW.md          # Research methodology and design
â”œâ”€â”€ SYSTEM_METHODOLOGY.md        # Implementation details
â”‚
â”œâ”€â”€ backend/                     # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/                 # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ experiment_clean.py    # Main experiment endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ explanations.py        # Narrative & counterfactual
â”‚   â”‚   â”‚   â””â”€â”€ admin.py               # Admin utilities
â”‚   â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ xgboost_service.py     # ML predictions
â”‚   â”‚   â”‚   â”œâ”€â”€ shap_service.py        # SHAP explanations
â”‚   â”‚   â”‚   â”œâ”€â”€ supabase_service.py    # Database operations
â”‚   â”‚   â”‚   â”œâ”€â”€ context_builder.py     # Narrative context
â”‚   â”‚   â”‚   â””â”€â”€ r2_service.py          # Model storage
â”‚   â”‚   â”œâ”€â”€ models/              # Data models
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”‚   â””â”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ migrations/              # Database migrations
â”‚   â”‚   â”œâ”€â”€ FINAL_CLEAN_SCHEMA.sql     # Production schema
â”‚   â”‚   â””â”€â”€ README.md                   # Schema documentation
â”‚   â”œâ”€â”€ scripts/                 # Utility scripts
â”‚   â”‚   â””â”€â”€ validate_installment_bias.py
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â””â”€â”€ README.md                # Backend documentation
â”‚
â”œâ”€â”€ frontend/                    # Next.js frontend
â”‚   â”œâ”€â”€ app/                     # Next.js 14 app directory
â”‚   â”‚   â”œâ”€â”€ page.tsx             # Landing page
â”‚   â”‚   â”œâ”€â”€ consent/             # Consent & baseline questionnaire
â”‚   â”‚   â”œâ”€â”€ experiment/          # Main experiment flow
â”‚   â”‚   â”‚   â””â”€â”€ personas/[personaId]/
â”‚   â”‚   â”‚       â””â”€â”€ layers/      # Layer rating interface
â”‚   â”‚   â”œâ”€â”€ results/             # Admin results dashboard
â”‚   â”‚   â””â”€â”€ layout.tsx           # Root layout
â”‚   â”œâ”€â”€ components/              # React components
â”‚   â”‚   â”œâ”€â”€ layers/              # Explanation layer components
â”‚   â”‚   â”‚   â”œâ”€â”€ Layer1Baseline.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Layer2Dashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Layer3Narrative.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Layer4Counterfactual.tsx
â”‚   â”‚   â”‚   â””â”€â”€ dashboard/       # Dashboard subcomponents
â”‚   â”‚   â””â”€â”€ ui/                  # Shared UI components
â”‚   â”œâ”€â”€ lib/                     # Utilities and data
â”‚   â”‚   â”œâ”€â”€ personas.ts          # Persona definitions
â”‚   â”‚   â””â”€â”€ categoricalMetadata.ts
â”‚   â”œâ”€â”€ package.json             # Node dependencies
â”‚   â””â”€â”€ README.md                # Frontend documentation
â”‚
â””â”€â”€ .gitignore                   # Git ignore rules
```

---

## ðŸ”¬ Research Methodology

### **Participants**
- Target: Bank employees, credit analysts, financial advisors
- Sample size: N = [target sample size]
- Recruitment: [recruitment method]

### **Procedure**
1. **Consent & Demographics** (5 min)
   - Informed consent
   - Background questionnaire (6 questions)
   - AI familiarity and trust baseline

2. **Persona 1: Maria** (15 min)
   - Borderline APPROVED case (53% confidence)
   - View and rate all 4 explanation layers
   - Post-persona questionnaire

3. **Persona 2: Jonas** (15 min)
   - Borderline REJECTED case (47% confidence)
   - View and rate all 4 explanation layers
   - Post-persona questionnaire

4. **Completion** (2 min)
   - Thank you message
   - Debrief information

**Total Time:** ~35-40 minutes per participant

### **Data Collected**

**Per Layer (3 ratings Ã— 4 layers Ã— 2 personas = 24 ratings):**
- Understanding (1-5 Likert)
- Communicability (1-5 Likert)
- Mental Ease (1-5 Likert, inverted cognitive load)
- Time spent (seconds)
- Optional comment

**Per Persona (2 questionnaires):**
- Most helpful layer
- Most trusted layer
- Best for customer communication
- Overall intuitiveness (1-5)
- AI usefulness (1-5)
- Improvement suggestions (open-ended)

---

## ðŸ“Š Data Analysis

### **Database Schema**
- `sessions`: Consent and baseline data
- `predictions`: AI predictions and SHAP values
- `layer_ratings`: Per-layer ratings (24 per participant)
- `post_questionnaires`: Post-persona feedback (2 per participant)

### **Analysis Views**
- `experiment_complete_data`: Aggregated session data
- `layer_performance_analysis`: Per-layer statistics with mean/stddev

### **Statistical Tests**
- Repeated measures ANOVA for layer comparisons
- Post-hoc pairwise comparisons (Bonferroni correction)
- Correlation analysis between dimensions
- Qualitative thematic analysis of comments

---

## ðŸ›¡ï¸ Ethical Considerations

### **Fairness & Bias**
- **Protected characteristics excluded:** Gender, nationality, foreign worker status
- **Bias validation:** Installment rate bias detected and documented
- **Transparency:** All SHAP values and model decisions fully disclosed
- **Fairness statement:** Included in all narrative explanations

### **Data Privacy**
- No personally identifiable information collected
- Anonymous session IDs
- Secure database with RLS policies
- GDPR compliant

### **Informed Consent**
- Clear explanation of study purpose
- Right to withdraw at any time
- Data usage transparency
- Debrief information provided

---

## ðŸ“ˆ Key Findings

[To be completed after data collection and analysis]

---

## ðŸ”§ Technical Details

### **ML Model**
- **Algorithm:** XGBoost Classifier
- **Dataset:** German Credit Dataset (1994), 1000 samples
- **Features:** 20 features (7 numeric, 13 categorical)
- **Performance:** [accuracy, precision, recall, F1]
- **Explainability:** SHAP TreeExplainer

### **Explanation Generation**
- **SHAP values:** Computed per prediction
- **Global context:** Statistical benchmarks from training data
- **Narrative generation:** OpenAI GPT-4o-mini with structured prompts
- **Counterfactuals:** Heuristic-based minimal changes

### **Frontend Technologies**
- **Framework:** Next.js 14 (App Router)
- **Language:** TypeScript
- **Styling:** TailwindCSS
- **Animations:** Framer Motion
- **Charts:** Recharts
- **State:** React hooks

### **Backend Technologies**
- **Framework:** FastAPI
- **ML:** XGBoost, SHAP
- **Database:** Supabase (PostgreSQL)
- **Storage:** Cloudflare R2
- **LLM:** OpenAI GPT-4o-mini

---

## ðŸ“š References

1. Lundberg, S. M., & Lee, S. I. (2017). A unified approach to interpreting model predictions. *Advances in Neural Information Processing Systems*, 30.

2. Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). "Why should I trust you?" Explaining the predictions of any classifier. *Proceedings of the 22nd ACM SIGKDD*, 1135-1144.

3. Miller, T. (2019). Explanation in artificial intelligence: Insights from the social sciences. *Artificial Intelligence*, 267, 1-38.

4. [Add your thesis-specific references]

---

## ðŸ“ Citation

If you use this code or methodology in your research, please cite:

```bibtex
@mastersthesis{lindner2025explainable,
  author = {Lindner, Jakob},
  title = {Explainable AI in Credit Decision-Making: A Multi-Layer Approach},
  school = {[Your University]},
  year = {2025},
  type = {Master's Thesis}
}
```

---

## ðŸ“§ Contact

**Jakob Lindner**  
Email: [your.email@university.edu]  
GitHub: [@Jakolo6](https://github.com/Jakolo6)

---

## ðŸ“„ License

This project is part of a master's thesis and is provided for academic purposes.  
[Specify your license: MIT, Academic Use Only, etc.]

---

## ðŸ™ Acknowledgments

- [Your supervisor/advisor]
- [Your university/department]
- [Any funding sources]
- Open-source libraries: XGBoost, SHAP, FastAPI, Next.js, and many others

---

**Last Updated:** December 2025
