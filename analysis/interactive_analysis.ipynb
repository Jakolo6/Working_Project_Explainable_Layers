{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI Layers Master Thesis - Interactive Analysis\n",
    "\n",
    "This notebook allows you to explore your data interactively after running the extraction script.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, make sure you've run `extract_and_analyze.py` to generate the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('output/xai_layers_analysis_ready.csv')\n",
    "\n",
    "print(f\"Loaded {len(df)} observations from {df['session_id'].nunique()} participants\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df[['understanding_rating', 'communicability_rating', 'cognitive_load_rating', 'time_spent_seconds']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating distributions by interface\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics = ['understanding_rating', 'communicability_rating', 'cognitive_load_rating']\n",
    "titles = ['Understanding', 'Communicability', 'Cognitive Load']\n",
    "\n",
    "for ax, metric, title in zip(axes, metrics, titles):\n",
    "    df.boxplot(column=metric, by='interface_id', ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Interface')\n",
    "    ax.set_ylabel('Rating (1-5)')\n",
    "    \n",
    "plt.suptitle('Rating Distributions by Interface', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean ratings comparison\n",
    "means = df.groupby('interface_id')[['understanding_rating', 'communicability_rating', 'cognitive_load_rating']].mean()\n",
    "\n",
    "means.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Mean Ratings by Interface')\n",
    "plt.xlabel('Interface')\n",
    "plt.ylabel('Mean Rating (1-5)')\n",
    "plt.legend(title='Metric')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time spent by interface\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot(column='time_spent_seconds', by='interface_id')\n",
    "plt.title('Time Spent by Interface')\n",
    "plt.xlabel('Interface')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Layer Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count preferences\n",
    "preferences = pd.DataFrame({\n",
    "    'Most Helpful': df.groupby('most_helpful_layer')['session_id'].nunique(),\n",
    "    'Most Trusted': df.groupby('most_trusted_layer')['session_id'].nunique(),\n",
    "    'Best for Customer': df.groupby('best_for_customer')['session_id'].nunique()\n",
    "}).fillna(0)\n",
    "\n",
    "preferences.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Layer Preferences')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Preference Type')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPreference Counts:\")\n",
    "print(preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison by Decision Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings by decision outcome\n",
    "by_outcome = df.groupby(['interface_id', 'decision_outcome'])[['understanding_rating', 'communicability_rating', 'cognitive_load_rating']].mean()\n",
    "\n",
    "by_outcome.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Mean Ratings by Interface and Decision Outcome')\n",
    "plt.xlabel('Interface × Decision')\n",
    "plt.ylabel('Mean Rating')\n",
    "plt.legend(title='Metric')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison by Role Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings by role group\n",
    "by_role = df.groupby(['interface_id', 'role_group'])[['understanding_rating', 'communicability_rating', 'cognitive_load_rating']].mean()\n",
    "\n",
    "by_role.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Mean Ratings by Interface and Role Group')\n",
    "plt.xlabel('Interface × Role')\n",
    "plt.ylabel('Mean Rating')\n",
    "plt.legend(title='Metric')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr_cols = ['understanding_rating', 'communicability_rating', 'cognitive_load_rating', \n",
    "             'time_spent_seconds', 'overall_intuitiveness', 'ai_usefulness']\n",
    "\n",
    "corr = df[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Analysis\n",
    "\n",
    "Add your own analysis cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom analysis here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
